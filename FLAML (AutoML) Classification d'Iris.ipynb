{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd96HBMBOP5++OJeHzl2uq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Pré-requis : Installation**"
      ],
      "metadata": {
        "id": "J6Z13iX8Z3Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrtV1YSkY93v",
        "outputId": "6c605704-a4c1-4889-a073-78e047444dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flaml\n",
            "  Downloading FLAML-1.1.2-py3-none-any.whl (222 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.3/222.3 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.8/dist-packages (from flaml) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.8/dist-packages (from flaml) (1.0.2)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.8/dist-packages (from flaml) (0.90)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from flaml) (1.3.5)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from flaml) (1.7.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=2.3.1->flaml) (0.38.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->flaml) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24->flaml) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24->flaml) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->flaml) (1.15.0)\n",
            "Installing collected packages: lightgbm, flaml\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed flaml-1.1.2 lightgbm-3.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Import et Initialisation de l'AutoML**"
      ],
      "metadata": {
        "id": "GwG0znsyaC1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSc9gcJbY2SL"
      },
      "outputs": [],
      "source": [
        "from flaml import AutoML\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Initialisation d'une instance autoML\n",
        "automl = AutoML()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ici, on importe notre jeu de donnée via la librairie sklearn.datasets, prenons l'exemple d'un problème de classification avec le dataset iris.\n",
        "\n",
        "Les données d'entrainement peuvent être une array numpy ou un dataframe pandas.\n",
        "\n",
        "Les données d'iris contiennent 3 types de fleurs, et ont des features spécifiques comme la longueur et la largeur des pétales/sépales."
      ],
      "metadata": {
        "id": "m5TG16e-af1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Spécification des paramètres de l'AutoML**"
      ],
      "metadata": {
        "id": "usU2QiaYavYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous avons ici plusieurs paramètres de l'AutoML : \n",
        "\n",
        "Si nous spécifions aucun des paramètres, il prendra les paramètres par défaut, et prendra plus de temps pour rechercher le meilleur modèle et les hyperparamètres du modèle.\n",
        "<br><br>\n",
        "Le paramètre \"**task**\" permet de spécifier le problème de machine learning.\n",
        "Il peut être regression, ts_forecast, summarization... Ici, il s'agit d'un probleme de classification.\n",
        "<br><br>\n",
        "Ensuite, le paramètre \"**time_budget**\" est optionnel, c'est un paramètre pour limiter le temps la recherche du modèle de et de ses hyperparamètres.  L'unité en seconde et pour l'exemple, nous avons spécifié 20 secondes.\n",
        "\n",
        "Il existe un autre paramètre qui est \"**max_iter**\", pour limiter le maximum de modèles à essayer dans le processus d'AutoML.\n",
        "<br><br>\n",
        "La métrique d'optimisation est spécifiée via le paramètre \"**metric**\". Il peut être soit une metrique existante, soit une fonction définie par l'utilisateur. On y trouve, log_loss pour la classification multi-class, roc_auc pour la classification binaire, mse pour l'erreur quadratique moyenne... Ici, nous avons utilisé la metrique : Accuracy.\n",
        "<br><br>\n",
        "Les essais sont loggués dans un fichier via le paramètre \"**log_file_name**\": iris.log, sous la forme d'un fichier JSON.\n"
      ],
      "metadata": {
        "id": "Wq2eICNCbVCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paramètre de l'autoML\n",
        "automl_settings = {\n",
        "    \"task\": 'classification',\n",
        "    \"time_budget\": 20,\n",
        "    \"metric\": 'accuracy',\n",
        "    \"log_file_name\": \"iris.log\",\n",
        "}"
      ],
      "metadata": {
        "id": "nBKKRGNqaXaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Entrainement de l'autoML**"
      ],
      "metadata": {
        "id": "hJdx_rIcf1N8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, le jeu de donnée est considéré comme un array numpy, on spécifie dans la fonction \"**fit**\" : les données d'entrainements X et y et les paramètres de notre AutoML.\n",
        "\n",
        "Affichons le meilleur des modèles : "
      ],
      "metadata": {
        "id": "xP5FvgF6g7S2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = load_iris(return_X_y=True)\n",
        "automl.fit(X_train=X_train, y_train=y_train,\n",
        "           **automl_settings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulCkCnllfumr",
        "outputId": "f5a31c23-5e0e-406b-9ffe-3342d4254fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.automl: 02-07 16:15:36] {2716} INFO - task = classification\n",
            "[flaml.automl.automl: 02-07 16:15:36] {2718} INFO - Data split method: stratified\n",
            "[flaml.automl.automl: 02-07 16:15:36] {2721} INFO - Evaluation method: cv\n",
            "[flaml.automl.automl: 02-07 16:15:36] {2848} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl.automl: 02-07 16:15:36] {2994} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3461} INFO - Estimated sufficient time budget=497s. Estimated necessary time budget=11s.\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.1s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.1s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.3s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 6, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.3s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.4s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.5s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.5s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3508} INFO -  at 0.6s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:36] {3323} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 0.6s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 0.6s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 0.7s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 0.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 17, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 0.8s,\testimator extra_tree's best error=0.1533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 18, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 0.9s,\testimator rf's best error=0.0867,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 0.9s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 20, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 1.0s,\testimator rf's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 1.1s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 1.1s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 1.2s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 24, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 1.2s,\testimator extra_tree's best error=0.1533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 1.3s,\testimator extra_tree's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 26, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 1.4s,\testimator rf's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 27, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3508} INFO -  at 1.5s,\testimator extra_tree's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:37] {3323} INFO - iteration 28, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 1.6s,\testimator extra_tree's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 1.7s,\testimator extra_tree's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 1.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 1.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 1.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 33, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 1.9s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 1.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 35, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 2.1s,\testimator rf's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 2.2s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 2.2s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 2.3s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 2.3s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 2.4s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 2.4s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 2.5s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3508} INFO -  at 2.5s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:38] {3323} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 2.6s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 2.7s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 2.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 2.8s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 2.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 49, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 2.9s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 3.0s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 51, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 3.1s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 52, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 3.2s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 3.2s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 3.3s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 55, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 3.4s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 3.5s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 57, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3508} INFO -  at 3.6s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:39] {3323} INFO - iteration 58, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 3.7s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 3.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 60, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 3.8s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 3.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 62, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 3.9s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 4.0s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 64, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 4.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 65, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 4.2s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 4.2s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 67, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 4.3s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 68, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 4.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 69, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 4.5s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3508} INFO -  at 4.5s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:40] {3323} INFO - iteration 71, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3508} INFO -  at 4.6s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3323} INFO - iteration 72, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3508} INFO -  at 4.7s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3323} INFO - iteration 73, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3508} INFO -  at 4.8s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3323} INFO - iteration 74, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3508} INFO -  at 4.8s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3323} INFO - iteration 75, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3508} INFO -  at 4.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3323} INFO - iteration 76, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3508} INFO -  at 5.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3323} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3508} INFO -  at 5.1s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3323} INFO - iteration 78, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3508} INFO -  at 5.2s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:41] {3323} INFO - iteration 79, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:42] {3508} INFO -  at 6.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:42] {3323} INFO - iteration 80, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:43] {3508} INFO -  at 6.8s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:43] {3323} INFO - iteration 81, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:43] {3508} INFO -  at 7.1s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:43] {3323} INFO - iteration 82, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:43] {3508} INFO -  at 7.3s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:43] {3323} INFO - iteration 83, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:43] {3508} INFO -  at 7.4s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:43] {3323} INFO - iteration 84, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:43] {3508} INFO -  at 7.5s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:43] {3323} INFO - iteration 85, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3508} INFO -  at 7.6s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3323} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3508} INFO -  at 7.7s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3323} INFO - iteration 87, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3508} INFO -  at 7.8s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3323} INFO - iteration 88, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3508} INFO -  at 8.0s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3323} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3508} INFO -  at 8.0s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3323} INFO - iteration 90, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3508} INFO -  at 8.2s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3323} INFO - iteration 91, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3508} INFO -  at 8.3s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3323} INFO - iteration 92, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3508} INFO -  at 8.5s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3323} INFO - iteration 93, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3508} INFO -  at 8.5s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:44] {3323} INFO - iteration 94, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:45] {3508} INFO -  at 8.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:45] {3323} INFO - iteration 95, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:45] {3508} INFO -  at 8.8s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:45] {3323} INFO - iteration 96, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:45] {3508} INFO -  at 8.9s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:45] {3323} INFO - iteration 97, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:45] {3508} INFO -  at 9.1s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:45] {3323} INFO - iteration 98, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:45] {3508} INFO -  at 9.4s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:45] {3323} INFO - iteration 99, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:46] {3508} INFO -  at 10.5s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:46] {3323} INFO - iteration 100, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:46] {3508} INFO -  at 10.6s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:46] {3323} INFO - iteration 101, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3508} INFO -  at 10.7s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3323} INFO - iteration 102, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3508} INFO -  at 10.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3323} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3508} INFO -  at 10.9s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3323} INFO - iteration 104, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3508} INFO -  at 11.0s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3323} INFO - iteration 105, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3508} INFO -  at 11.2s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3323} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3508} INFO -  at 11.3s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3323} INFO - iteration 107, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3508} INFO -  at 11.4s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3323} INFO - iteration 108, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3508} INFO -  at 11.6s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:47] {3323} INFO - iteration 109, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3508} INFO -  at 12.0s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3323} INFO - iteration 110, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3508} INFO -  at 12.1s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3323} INFO - iteration 111, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3508} INFO -  at 12.2s,\testimator extra_tree's best error=0.0533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3323} INFO - iteration 112, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3508} INFO -  at 12.3s,\testimator extra_tree's best error=0.0533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3323} INFO - iteration 113, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3508} INFO -  at 12.4s,\testimator extra_tree's best error=0.0533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3323} INFO - iteration 114, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3508} INFO -  at 12.5s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3323} INFO - iteration 115, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3508} INFO -  at 12.6s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:48] {3323} INFO - iteration 116, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 12.6s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 117, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 12.7s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 118, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 12.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 119, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 12.9s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 120, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.0s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 121, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.0s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 122, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.1s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 123, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.1s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 124, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.2s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 125, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 126, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 127, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 128, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.4s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 129, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.5s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 130, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3508} INFO -  at 13.5s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:49] {3323} INFO - iteration 131, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 13.6s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 132, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 13.7s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 133, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 13.7s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 134, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 13.8s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 135, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 13.9s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 136, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 14.0s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 137, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 14.1s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 138, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 14.1s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 139, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 14.2s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 140, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 14.3s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 141, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 14.4s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 142, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 14.5s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 143, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3508} INFO -  at 14.5s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:50] {3323} INFO - iteration 144, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 14.6s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 145, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 14.7s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 146, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 14.8s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 147, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 14.8s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 14.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 149, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 14.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 150, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 15.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 151, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 15.0s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 152, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 15.1s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 153, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 15.2s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 154, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 15.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 155, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 15.2s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 156, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 15.3s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 157, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 15.4s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 158, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 15.5s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 159, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3508} INFO -  at 15.5s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:51] {3323} INFO - iteration 160, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 15.6s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 161, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 15.7s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 162, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 15.8s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 163, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 15.9s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 164, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 15.9s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 165, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 16.0s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 166, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 16.1s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 167, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 16.2s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 168, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 16.3s,\testimator xgb_limitdepth's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 169, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 16.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 170, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 16.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 171, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 16.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 172, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3508} INFO -  at 16.5s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:52] {3323} INFO - iteration 173, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 16.6s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 174, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 16.7s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 175, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 16.7s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 176, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 16.8s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 177, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 16.9s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 178, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 16.9s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 179, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 17.0s,\testimator extra_tree's best error=0.0467,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 180, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 17.1s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 181, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 17.2s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 182, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 17.3s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 183, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 17.4s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 184, current learner xgboost\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3508} INFO -  at 17.5s,\testimator xgboost's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:53] {3323} INFO - iteration 185, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:54] {3508} INFO -  at 17.7s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:54] {3323} INFO - iteration 186, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:54] {3508} INFO -  at 17.8s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:54] {3323} INFO - iteration 187, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:55] {3508} INFO -  at 19.2s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:55] {3323} INFO - iteration 188, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:55] {3508} INFO -  at 19.3s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:55] {3323} INFO - iteration 189, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:55] {3508} INFO -  at 19.4s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:55] {3323} INFO - iteration 190, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:55] {3508} INFO -  at 19.5s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:55] {3323} INFO - iteration 191, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:55] {3508} INFO -  at 19.5s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:55] {3323} INFO - iteration 192, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3508} INFO -  at 19.6s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3323} INFO - iteration 193, current learner extra_tree\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3508} INFO -  at 19.7s,\testimator extra_tree's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3323} INFO - iteration 194, current learner xgb_limitdepth\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3508} INFO -  at 19.8s,\testimator xgb_limitdepth's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3323} INFO - iteration 195, current learner rf\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3508} INFO -  at 19.9s,\testimator rf's best error=0.0400,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3323} INFO - iteration 196, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3508} INFO -  at 19.9s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3323} INFO - iteration 197, current learner lgbm\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3508} INFO -  at 20.0s,\testimator lgbm's best error=0.0333,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3323} INFO - iteration 198, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.automl: 02-07 16:15:56] {3508} INFO -  at 20.0s,\testimator lrl1's best error=0.0667,\tbest estimator lgbm's best error=0.0333\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3772} INFO - retrain lgbm for 0.0s\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3779} INFO - retrained model: LGBMClassifier(learning_rate=0.41398771112970667, max_bin=31,\n",
            "               min_child_samples=9, n_estimators=4, num_leaves=4,\n",
            "               reg_alpha=0.0024255899041695415, reg_lambda=1.9151305043222606,\n",
            "               verbose=-1)\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3024} INFO - fit succeeded\n",
            "[flaml.automl.automl: 02-07 16:15:56] {3025} INFO - Time taken to find the best model: 13.219608068466187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(automl.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLkSXfvuhhKN",
        "outputId": "e817ee24-1fb9-4b45-967e-54f7a3997f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<flaml.automl.model.LGBMEstimator object at 0x7f76b1361dc0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il nous renvoie un modèle de **LGMestimator** pour ce problème de de classification.\n",
        "\n",
        "Affichons le modèle avec les hyperparamètres avec le paramètre \"**estimator**\" :"
      ],
      "metadata": {
        "id": "s95w-ZPFiItB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(automl.model.estimator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYxbtVTQhggd",
        "outputId": "f4a49138-cbe2-467c-fb67-e2d4a44536a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBMClassifier(learning_rate=0.41398771112970667, max_bin=31,\n",
            "               min_child_samples=9, n_estimators=4, num_leaves=4,\n",
            "               reg_alpha=0.0024255899041695415, reg_lambda=1.9151305043222606,\n",
            "               verbose=-1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut également les afficher séparement :"
      ],
      "metadata": {
        "id": "62SnRghHihqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(automl.best_estimator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djs6d3OYhw8z",
        "outputId": "6617c18b-a4e4-476f-a20a-d2d5ca7de819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lgbm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(automl.best_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxeaxoGUis4D",
        "outputId": "345127cc-b0d7-4226-bc25-3ef1d111071f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.41398771112970667, 'log_max_bin': 5, 'colsample_bytree': 1.0, 'reg_alpha': 0.0024255899041695415, 'reg_lambda': 1.9151305043222606}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('La meilleur Accuracy sur les données de validation : {0:.4g}'.format(1-automl.best_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqYt8WwOnFzH",
        "outputId": "5097a5f3-7e01-43e3-dc15-30d20fb27438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La meilleur Accuracy sur les données de validation : 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Prédiction des données**\n",
        "\n",
        "Faisons une prédiction des données avec notre modèles d'AutoML :"
      ],
      "metadata": {
        "id": "ZuCcedHCmFa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(automl.predict_proba(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Skrj7c7FmAxl",
        "outputId": "fe3aa972-c937-4537-c537-fa28e91b908c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.90813319 0.04706318 0.04480363]\n",
            " [0.86660532 0.06833783 0.06505685]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.86660532 0.06833783 0.06505685]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.86660532 0.06833783 0.06505685]\n",
            " [0.86660532 0.06833783 0.06505685]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.72113841 0.21985961 0.05900198]\n",
            " [0.61145089 0.31982058 0.06872852]\n",
            " [0.86660532 0.06833783 0.06505685]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.86660532 0.06833783 0.06505685]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.85487129 0.06741252 0.07771619]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.72113841 0.21985961 0.05900198]\n",
            " [0.61145089 0.31982058 0.06872852]\n",
            " [0.86660532 0.06833783 0.06505685]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.90813319 0.04706318 0.04480363]\n",
            " [0.06057832 0.84943522 0.08998646]\n",
            " [0.05189024 0.88159917 0.06651059]\n",
            " [0.06715    0.62966505 0.30318494]\n",
            " [0.05198571 0.88322123 0.06479305]\n",
            " [0.05189024 0.88159917 0.06651059]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.07593402 0.78359194 0.14047404]\n",
            " [0.16595685 0.77703957 0.05700357]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.07007261 0.87681131 0.05311608]\n",
            " [0.08665265 0.85092365 0.0624237 ]\n",
            " [0.05189024 0.88159917 0.06651059]\n",
            " [0.06531087 0.8708068  0.06388233]\n",
            " [0.06057832 0.84943522 0.08998646]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.05189024 0.88159917 0.06651059]\n",
            " [0.06604596 0.88060796 0.05334608]\n",
            " [0.05117215 0.86939907 0.07942877]\n",
            " [0.05198571 0.88322123 0.06479305]\n",
            " [0.08445982 0.30669345 0.60884673]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.06715    0.62966505 0.30318494]\n",
            " [0.06057832 0.84943522 0.08998646]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.05601172 0.78540189 0.1585864 ]\n",
            " [0.06796173 0.14321443 0.78882384]\n",
            " [0.05189024 0.88159917 0.06651059]\n",
            " [0.06604596 0.88060796 0.05334608]\n",
            " [0.05198571 0.88322123 0.06479305]\n",
            " [0.06531087 0.8708068  0.06388233]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.0677148  0.30565125 0.62663395]\n",
            " [0.06917108 0.86553059 0.06529833]\n",
            " [0.06763568 0.84567192 0.0866924 ]\n",
            " [0.05926963 0.8310846  0.10964577]\n",
            " [0.05198571 0.88322123 0.06479305]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.05198571 0.88322123 0.06479305]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.16595685 0.77703957 0.05700357]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.13506451 0.80582054 0.05911494]\n",
            " [0.05257926 0.89330546 0.05411528]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.14189222 0.37947688 0.47863091]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.06796173 0.14321443 0.78882384]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.07895224 0.47280937 0.4482384 ]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.07899536 0.19182555 0.72917909]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.07899536 0.19182555 0.72917909]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.08445982 0.30669345 0.60884673]\n",
            " [0.07899536 0.19182555 0.72917909]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.0677148  0.30565125 0.62663395]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.0677148  0.30565125 0.62663395]\n",
            " [0.0677148  0.30565125 0.62663395]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.08445982 0.30669345 0.60884673]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.06796173 0.14321443 0.78882384]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]\n",
            " [0.04728021 0.05821908 0.89450071]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin,\n",
        "\n",
        "On peut également tracer la fonction loss au fil du temps. \n",
        "\n",
        "La fonction loss quantifie l'écart entre les prévisions du modèle et les observations réelles du jeu de donnée utilisé pendant l'entraînement."
      ],
      "metadata": {
        "id": "afru4VTBk_gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flaml.automl.data import get_output_from_log\n",
        "\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = get_output_from_log(filename=\"iris.log\", time_budget=10)"
      ],
      "metadata": {
        "id": "hIt5IA3Tglhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.title(\"Courbe d'apprentissage\")\n",
        "plt.xlabel(\"Temps (s)\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "m44pv4eTZJ-Y",
        "outputId": "124e8232-eb89-4d1e-b061-d6887ac114ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion :**    \n",
        "\n",
        "Flaml est une librairie facile à utiliser pour faire de l'AutoML. \n",
        "\n",
        "Nous avons vu qu'on pouvait facilement paramétrer notre AutoML en plaçant des conditions sur le temps de recherche du modèles et des hyperparamètres, qui dépend de la taille de notre jeu de données.\n",
        "\n",
        "Nous avons vu comment l'AutoML nous propose facilement un modèle de machine learning avec les hyperparamètres optimisée. \n",
        "\n",
        "Nous avons l'accuracy de notre modèle et vérifier cela sur les données de prédictions.\n",
        "\n",
        "Et enfin, nous avons afficher la progression d'apprentissage du modèle en fonction du temps d'apprentissage fixé dans les paramètres de l'AutoML."
      ],
      "metadata": {
        "id": "wWKBn29cnk8X"
      }
    }
  ]
}