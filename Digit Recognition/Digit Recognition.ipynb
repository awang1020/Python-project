{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance de chiffres manuscrites à l'aide du Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### Le jeu de données MNIST\n",
    "\n",
    "Parmi les milliers de jeux de données disponibles sur le marché, MNIST est le jeu de données le plus populaire pour les amateurs d'apprentissage automatique et d'apprentissage profond. Plus de 60.000 images d'entraînement de chiffres manuscrits de zéro à neuf et plus de 10.000 images de test sont présentes dans le jeu de données MNIST. \n",
    "\n",
    "L'ensemble de données MNIST comprend donc 10 classes différentes (pour chaque chiffre, de 0 à 9). <br>\n",
    "Les images de chiffres manuscrits sont présentées sous la forme d'une matrice de 28×28 où chaque cellule est constituée d'une valeur de pixel en niveaux de gris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 17:34:30.281732: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to split the data of training and testing sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La bibliothèque Keras contient déjà de nombreux jeux de données et MNIST est l'un d'entre eux. \n",
    "\n",
    "Nous appelons la fonction mnist.load_data() pour obtenir les données d'entraînement avec leurs étiquettes et également les données de test avec leurs étiquettes.\n",
    "\n",
    "Affichons quelques exemples : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe50bc74130>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,2))\n",
    "plt.imshow(x_train[2301])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe50c64a5b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,2))\n",
    "plt.imshow(x_train[25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle de deep learning ne peut prendre les données d'image en entrée directement.\n",
    "\n",
    "Nous devons effectuer quelques traitements pour rendre les données prêtes pour nos réseaux neuronnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dimension des données d'entrainement est de (60000, 28, 28). \n",
    "\n",
    "Une dimension supplémentaire est nécessaire pour le modèle CNN, nous remodelons donc la matrice pour lui donner la forme (60000, 28, 28, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est temps de créer le modèle CNN pour ce projet de science des données basé sur Python. \n",
    "\n",
    "Une couche convolutive (convolutional layer) et des pooling layers sont les deux roues d'un modèle CNN. La raison du succès du CNN pour les problèmes de classification d'images est sa faisabilité avec des données structurées en grille. \n",
    "\n",
    "Nous utiliserons l'optimiseur Adadelta pour la compilation du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 17:34:40.335521: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entrainement du modèle\n",
    "\n",
    "Pour commencer l'entraînement du modèle, nous pouvons simplement appeler la fonction model.fit() de Keras. Elle prend les données d'entraînement, les données de validation, les époques et la taille du lot comme paramètres.\n",
    "\n",
    "L'entraînement du modèle prend un certain temps. Après un entraînement réussi du modèle, nous pouvons enregistrer les poids et la définition du modèle dans le fichier 'mnist.h5'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 116s 246ms/step - loss: 2.2754 - accuracy: 0.1665 - val_loss: 2.2397 - val_accuracy: 0.4034\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 121s 258ms/step - loss: 2.2174 - accuracy: 0.2973 - val_loss: 2.1665 - val_accuracy: 0.5492\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 123s 262ms/step - loss: 2.1387 - accuracy: 0.4111 - val_loss: 2.0645 - val_accuracy: 0.6487\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 140s 299ms/step - loss: 2.0280 - accuracy: 0.5097 - val_loss: 1.9221 - val_accuracy: 0.7097\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 124s 264ms/step - loss: 1.8765 - accuracy: 0.5809 - val_loss: 1.7293 - val_accuracy: 0.7645\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 110s 235ms/step - loss: 1.6825 - accuracy: 0.6373 - val_loss: 1.4904 - val_accuracy: 0.8017\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 104s 222ms/step - loss: 1.4607 - accuracy: 0.6765 - val_loss: 1.2372 - val_accuracy: 0.8186\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 105s 224ms/step - loss: 1.2518 - accuracy: 0.7049 - val_loss: 1.0173 - val_accuracy: 0.8294\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 111s 237ms/step - loss: 1.0859 - accuracy: 0.7214 - val_loss: 0.8530 - val_accuracy: 0.8365\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 101s 214ms/step - loss: 0.9596 - accuracy: 0.7390 - val_loss: 0.7371 - val_accuracy: 0.8447\n",
      "The model has successfully trained\n",
      "Saving the bot as my_model.h5\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, \n",
    "                 y_train,\n",
    "                 batch_size=128,\n",
    "                 epochs=10,\n",
    "                 verbose=1,\n",
    "                 validation_data=(x_test, y_test))\n",
    "\n",
    "print(\"The model has successfully trained\")\n",
    "model.save('my_model.h5')\n",
    "print(\"Saving the bot as my_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7371471524238586\n",
      "Test accuracy: 0.8446999788284302\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
